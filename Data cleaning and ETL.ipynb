{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "beca05d3-116e-46b8-af79-ed4f22597264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Crash ID State  Month  Year Dayweek      Time Crash Type  \\\n",
      "0  20241115   NSW     12  2024  Friday  04:00:00     Single   \n",
      "1  20241125   NSW     12  2024  Friday  06:15:00     Single   \n",
      "2  20246013   Tas     12  2024  Friday  09:43:00   Multiple   \n",
      "3  20241002   NSW     12  2024  Friday  10:35:00   Multiple   \n",
      "4  20242261   Vic     12  2024  Friday  11:30:00   Multiple   \n",
      "\n",
      "   Number Fatalities Bus \\nInvolvement Heavy Rigid Truck Involvement  \\\n",
      "0                  1                No                            No   \n",
      "1                  1                No                            No   \n",
      "2                  1                No                            No   \n",
      "3                  1                No                            No   \n",
      "4                  1                -9                            -9   \n",
      "\n",
      "  Articulated Truck Involvement Speed Limit National Remoteness Areas  \\\n",
      "0                            No         100  Inner Regional Australia   \n",
      "1                            No          80  Inner Regional Australia   \n",
      "2                            No          50  Inner Regional Australia   \n",
      "3                            No         100  Outer Regional Australia   \n",
      "4                            -9          -9                   Unknown   \n",
      "\n",
      "                            SA4 Name 2021 National LGA Name 2021  \\\n",
      "0                                Riverina            Wagga Wagga   \n",
      "1  Sydney - Baulkham Hills and Hawkesbury             Hawkesbury   \n",
      "2               Launceston and North East      Northern Midlands   \n",
      "3              New England and North West      Armidale Regional   \n",
      "4                                     NaN                    NaN   \n",
      "\n",
      "          National Road Type Christmas Period Easter Period Day of week  \\\n",
      "0              Arterial Road              Yes            No     Weekday   \n",
      "1                 Local Road               No            No     Weekday   \n",
      "2                 Local Road              Yes            No     Weekday   \n",
      "3  National or State Highway               No            No     Weekday   \n",
      "4               Undetermined               No            No     Weekday   \n",
      "\n",
      "  Time of Day  \n",
      "0       Night  \n",
      "1         Day  \n",
      "2         Day  \n",
      "3         Day  \n",
      "4         Day  \n",
      "   Crash ID State  Month  Year Dayweek      Time Crash Type Bus Involvement  \\\n",
      "0  20241115   NSW     12  2024  Friday  04:00:00     Single              No   \n",
      "1  20241125   NSW     12  2024  Friday  06:15:00     Single              No   \n",
      "2  20246013   Tas     12  2024  Friday  09:43:00   Multiple              No   \n",
      "3  20241002   NSW     12  2024  Friday  10:35:00   Multiple              No   \n",
      "4  20242261   Vic     12  2024  Friday  11:30:00   Multiple              -9   \n",
      "\n",
      "  Heavy Rigid Truck Involvement Articulated Truck Involvement  ... Age  \\\n",
      "0                            No                            No  ...  74   \n",
      "1                            No                            No  ...  19   \n",
      "2                            No                            No  ...  33   \n",
      "3                            No                            No  ...  32   \n",
      "4                            -9                            -9  ...  62   \n",
      "\n",
      "  National Remoteness Areas                           SA4 Name 2021  \\\n",
      "0  Inner Regional Australia                                Riverina   \n",
      "1  Inner Regional Australia  Sydney - Baulkham Hills and Hawkesbury   \n",
      "2  Inner Regional Australia               Launceston and North East   \n",
      "3  Outer Regional Australia              New England and North West   \n",
      "4                   Unknown                                     NaN   \n",
      "\n",
      "   National LGA Name 2021         National Road Type Christmas Period  \\\n",
      "0             Wagga Wagga              Arterial Road              Yes   \n",
      "1              Hawkesbury                 Local Road               No   \n",
      "2       Northern Midlands                 Local Road              Yes   \n",
      "3       Armidale Regional  National or State Highway               No   \n",
      "4                     NaN               Undetermined               No   \n",
      "\n",
      "  Easter Period Age Group Day of week Time of day  \n",
      "0            No  65_to_74     Weekday       Night  \n",
      "1            No  17_to_25     Weekday         Day  \n",
      "2            No  26_to_39     Weekday         Day  \n",
      "3            No  26_to_39     Weekday         Day  \n",
      "4            No  40_to_64     Weekday         Day  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load original datasets\n",
    "crashes_df = pd.read_excel(r\"D:\\UWA\\Data_Warehousing\\Project 1\\bitre_fatal_crashes_dec2024.xlsx\", sheet_name=\"BITRE_Fatal_Crash\", header=4)\n",
    "fatalities_df = pd.read_excel(r\"D:\\UWA\\Data_Warehousing\\Project 1\\bitre_fatalities_dec2024.xlsx\", sheet_name=\"BITRE_Fatality\", header=4)\n",
    "\n",
    "# Show first 5 rows\n",
    "print(crashes_df.head(5))\n",
    "print(fatalities_df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "36b47dca-d463-4963-8f6c-699891737ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"Bus \\nInvolvement\" column to \"Bus Involvement\"\n",
    "crashes_df.rename(columns={\"Bus \\nInvolvement\": \"Bus Involvement\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2f0389d8-897f-4d0a-87b8-9d31873139be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51284, 20)\n",
      "(56874, 23)\n"
     ]
    }
   ],
   "source": [
    "print(crashes_df.shape)\n",
    "print(fatalities_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56801e50-641e-49d0-aa65-f6b04f88e5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crash ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.687400e+04</td>\n",
       "      <td>56874.000000</td>\n",
       "      <td>56874.000000</td>\n",
       "      <td>56874.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.007641e+07</td>\n",
       "      <td>6.596142</td>\n",
       "      <td>2004.158086</td>\n",
       "      <td>40.036414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.410814e+06</td>\n",
       "      <td>3.465712</td>\n",
       "      <td>10.417546</td>\n",
       "      <td>21.891551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.989100e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.995308e+07</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.003223e+07</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.013112e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.018501e+08</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crash ID         Month          Year           Age\n",
       "count  5.687400e+04  56874.000000  56874.000000  56874.000000\n",
       "mean   2.007641e+07      6.596142   2004.158086     40.036414\n",
       "std    2.410814e+06      3.465712     10.417546     21.891551\n",
       "min    1.989100e+07      1.000000   1989.000000     -9.000000\n",
       "25%    1.995308e+07      4.000000   1995.000000     22.000000\n",
       "50%    2.003223e+07      7.000000   2003.000000     35.000000\n",
       "75%    2.013112e+07     10.000000   2013.000000     56.000000\n",
       "max    2.018501e+08     12.000000   2024.000000    101.000000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "crashes_df.describe()\n",
    "fatalities_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "93ce9c06-119f-41af-8bde-76a2c0cfc961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¢ Total NaN in Crashes:\n",
      "SA4 Name 2021             39579\n",
      "National LGA Name 2021    39578\n",
      "Time                         39\n",
      "dtype: int64\n",
      "\n",
      "üî¢ Total NaN in Fatalities:\n",
      "SA4 Name 2021             44175\n",
      "National LGA Name 2021    44173\n",
      "Time                         43\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# absolute NaN counts as well\n",
    "print(\"\\nüî¢ Total NaN in Crashes:\")\n",
    "print(crashes_df.isna().sum()[crashes_df.isna().sum() > 0].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nüî¢ Total NaN in Fatalities:\")\n",
    "print(fatalities_df.isna().sum()[fatalities_df.isna().sum() > 0].sort_values(ascending=False))\n",
    "\n",
    "# Since these columns are not useful, we can ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1884619b-82fd-4ded-a4ba-6cb2207d5099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace common invalids with NaN - these invalid values has been noticed in data\n",
    "invalids = ['-9', -9, 'Unknown', '', ' ']\n",
    "crashes_df.replace(invalids, pd.NA, inplace=True)\n",
    "fatalities_df.replace(invalids, pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "04111d4d-d4fc-4078-adff-73c81b6f1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Missing % in Crashes:\n",
      "SA4 Name 2021                    80.18\n",
      "National LGA Name 2021           80.17\n",
      "National Remoteness Areas        79.58\n",
      "Heavy Rigid Truck Involvement    35.51\n",
      "Speed Limit                       2.60\n",
      "Bus Involvement                   0.12\n",
      "Articulated Truck Involvement     0.11\n",
      "Time                              0.08\n",
      "Time of Day                       0.08\n",
      "Day of week                       0.02\n",
      "dtype: float64\n",
      "\n",
      " Missing % in Fatalities:\n",
      "SA4 Name 2021                    80.62\n",
      "National LGA Name 2021           80.62\n",
      "National Remoteness Areas        80.04\n",
      "Heavy Rigid Truck Involvement    36.14\n",
      "Speed Limit                       2.61\n",
      "Age Group                         0.21\n",
      "Age                               0.20\n",
      "Bus Involvement                   0.12\n",
      "Articulated Truck Involvement     0.11\n",
      "Time                              0.08\n",
      "Time of day                       0.08\n",
      "Gender                            0.06\n",
      "Road User                         0.02\n",
      "Day of week                       0.02\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Show % of missing data (only > 0%)\n",
    "print(\"\\n Missing % in Crashes:\")\n",
    "missing_crash = crashes_df.isna().mean().round(4) * 100\n",
    "print(missing_crash[missing_crash > 0].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n Missing % in Fatalities:\")\n",
    "missing_fatal = fatalities_df.isna().mean().round(4) * 100\n",
    "print(missing_fatal[missing_fatal > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a4b849a-ca36-4a65-b2cc-4d0ab6897867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows missing critical fields\n",
    "crashes_df_clean = crashes_df.dropna(subset=['Time', 'Time of Day', 'Day of week', 'Speed Limit', 'Bus Involvement', 'Articulated Truck Involvement'], inplace=False)\n",
    "fatalities_df_clean = fatalities_df.dropna(subset=[ 'Road User', 'Time', 'Time of day', 'Gender', 'Day of week', 'Speed Limit', 'Age', 'Age Group'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c725fcae-bee6-434d-9cb5-6bf9c7b8c0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Missing % in Crashes:\n",
      "SA4 Name 2021                    79.83\n",
      "National LGA Name 2021           79.83\n",
      "National Remoteness Areas        79.24\n",
      "Heavy Rigid Truck Involvement    34.91\n",
      "dtype: float64\n",
      "\n",
      " Missing % in Fatalities:\n",
      "SA4 Name 2021                    80.24\n",
      "National LGA Name 2021           80.23\n",
      "National Remoteness Areas        79.66\n",
      "Heavy Rigid Truck Involvement    35.57\n",
      "Bus Involvement                   0.09\n",
      "Articulated Truck Involvement     0.08\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Show % of missing data (only > 0%) after dropping invalid rows\n",
    "print(\"\\n Missing % in Crashes:\")\n",
    "missing_crash = crashes_df_clean.isna().mean().round(4) * 100\n",
    "print(missing_crash[missing_crash > 0].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n Missing % in Fatalities:\")\n",
    "missing_fatal = fatalities_df_clean.isna().mean().round(4) * 100\n",
    "print(missing_fatal[missing_fatal > 0].sort_values(ascending=False))\n",
    "\n",
    "# Now we can see that critical columns don't have invalid records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "96293b3a-6d55-4c0e-be77-c462201070f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Crashes data loss % = 2.731846189844786 %\n",
      " Fatalities data loss % = 2.8853254562717585 %\n"
     ]
    }
   ],
   "source": [
    "# check % of data loss\n",
    "crashes_data_loss_per = ((crashes_df.shape[0]-crashes_df_clean.shape[0])*100)/crashes_df.shape[0]\n",
    "fatalities_data_loss_per = ((fatalities_df.shape[0]-fatalities_df_clean.shape[0])*100)/fatalities_df.shape[0]\n",
    "print(f\"\\n Crashes data loss % = { crashes_data_loss_per} %\")\n",
    "print(f\" Fatalities data loss % = { fatalities_data_loss_per} %\")\n",
    "\n",
    "### Both are less than 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b10285b-2135-4256-94ab-64c0cfc4c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets overwrite our original dataframes\n",
    "crashes_df = crashes_df_clean\n",
    "fatalities_df = fatalities_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "12f965d3-bc2a-4a85-9e74-b55af3590173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JHAKU\\AppData\\Local\\Temp\\ipykernel_28648\\3548154164.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  fatalities_df.fillna(\"Unknown\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Replace other nulls with 'Unknown'\n",
    "crashes_df.fillna(\"Unknown\", inplace=True)\n",
    "fatalities_df.fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e4ce3c2-de52-428c-916b-bbb864a0c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cleaned crashes: 49883 rows and 20 columns\n",
      " Cleaned fatalities: 55233 rows and 23 columns\n"
     ]
    }
   ],
   "source": [
    "# Final shape\n",
    "print(f\"\\n Cleaned crashes: {crashes_df.shape[0]} rows and {crashes_df.shape[1]} columns\")\n",
    "print(f\" Cleaned fatalities: {fatalities_df.shape[0]} rows and {fatalities_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ba8a644f-ff2f-4058-9128-58248f74bd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Data loaded into PostgreSQL successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load data into PostgreSQL using SQLAlchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "DB_USER = 'postgres'\n",
    "DB_PASS = 'test'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = 'Project_DW01'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "conn=engine.connect()\n",
    "\n",
    "# Load cleaned data into staging tables\n",
    "try:\n",
    "    crashes_df.to_sql('stg_crashes', engine, if_exists='replace', index=False)\n",
    "    fatalities_df.to_sql('stg_fatalities', engine, if_exists='replace', index=False)\n",
    "    print(\"\\n‚úÖ Data loaded into PostgreSQL successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Failed to load into PostgreSQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "32703219-bf99-4734-9c03-71f2842cac3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\jhaku\\anaconda3\\lib\\site-packages (2.9.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dfadd777-7935-4d16-8834-fc000314c322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lga_name</th>\n",
       "      <th>dwelling_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>25430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armidale Regional</td>\n",
       "      <td>12955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ballina</td>\n",
       "      <td>20889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balranald</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bathurst Regional</td>\n",
       "      <td>18458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lga_name dwelling_count\n",
       "0             Albury          25430\n",
       "1  Armidale Regional          12955\n",
       "2            Ballina          20889\n",
       "3          Balranald           1091\n",
       "4  Bathurst Regional          18458"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dwelling count csv\n",
    "dwelling_df = pd.read_csv(\n",
    "    r\"D:\\UWA\\Data_Warehousing\\Project 1\\LGA (count of dwellings).csv\",\n",
    "    skiprows=11,\n",
    "    usecols=[0, 1],\n",
    "    names=['lga_name', 'dwelling_count']\n",
    ")\n",
    "\n",
    "dwelling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4b612b70-7248-479a-8508-a3e18f23d018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 2)\n",
      "\n",
      " Missing % in Crashes:\n",
      "dwelling_count    0.53\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check total number of rows and columns\n",
    "print(dwelling_df.shape)\n",
    "\n",
    "# Check % of missing data (only > 0%) after dropping invalid rows\n",
    "print(\"\\n Missing % in Crashes:\")\n",
    "missing_dwelling_count = dwelling_df.isna().mean().round(4) * 100\n",
    "print(missing_dwelling_count[missing_dwelling_count > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c9b3be46-f202-4f42-98e2-fd0289fc1947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 2)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since 0.53 is very less, we can simply drop it\n",
    "dwelling_df.dropna(subset=['lga_name', 'dwelling_count'], inplace=True)\n",
    "\n",
    "#Check rows number after dropping invalid records\n",
    "dwelling_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0564169c-3993-4af2-8da0-0abd3764533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate records\n",
    "dwelling_df = dwelling_df.dropna().drop_duplicates()\n",
    "dwelling_df = dwelling_df[dwelling_df['dwelling_count'].apply(lambda x: str(x).isdigit())]\n",
    "dwelling_df['dwelling_count'] = dwelling_df['dwelling_count'].astype(int)\n",
    "dwelling_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "20168d26-32f2-457c-ac11-2f2fac7dac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data loaded into PostgreSQL successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load data into staging table\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "DB_USER = 'postgres'\n",
    "DB_PASS = 'test'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = 'Project_DW01'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "conn=engine.connect()\n",
    "\n",
    "# Load cleaned data into staging tables\n",
    "try:\n",
    "    dwelling_df.to_sql('stg_dwelling_count', engine, if_exists='replace', index=False)\n",
    "    print(\"\\n Data loaded into PostgreSQL successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n Failed to load into PostgreSQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcef40-dd64-4ca6-9a29-081e6105f57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
